# powerplant-coding-challenge

## Deploy and run locally

### Prerequisites

This package requires `python` and its depency and package manager `poetry` to be installed on your local machine.

### Execution

- Open a terminal in the root directory, which contains `pyproject.toml`
- Install the dependencies in a virtual environment using `poetry`

```bash
poetry install
```

- Then, run the following command to execute

```bash
poetry run python -m powerplant_coding_challenge.app
```

## Deploy and run in a container with Docker

### Prerequisites - Container

Docker should be installed on your local machine.

### Execution - Container

- Open a terminal in the root directory, which contains `Dockerfile`

- build a docker image with the following command:
  
```bash
docker build -t powerplant_coding_challenge .
```

- Then, run the following command to execute

```bash
docker run powerplant_coding_challenge
```

## Use the package

The running package will have exposed an ip address on port 8888. The only request available to this API is a POST request on endpoint `/productionplan`

It accepts a body of json type (`Content-Type: application/json`), in the same flavour as `payload1.json`, `payload2.json`, or `payload3.json`, that were provided.

For example in the case of a local install, the ip address should be `127.0.0.1`, so a request would be : `POST http://172.17.0.2:8888/productionplan`

If the body is well formatted, it should return a response similar to the `response3.json` file that was provided

## Description of the code

### src/powerplant_coding_challenge

#### `app.py`

Being an API, I chose for this as an entrypoint rather than the natural `main.py`.

It initiates an API with Flask, and sets the method `POST` on endpoint `/productionplan`

#### `utils`

This script is used to extract values from the payload and sets them as python variables: numeric values for `fuels` and `load`, and a Pandas DataFrame for `powerplants`

#### `powerplant_optimizer`

This script contains the algorithm:

- it creates new values such as `cost` (`price * efficiency`), or the power generated by a windpark, depending on the `wind%`
- It then sorts by `cost`. Other fields are used but this is a subjective choice open to debate (more on that in the **Doubts** section below)
- Starting from the value in `load` it substracts `pmax` in a cumulative way until getting at 0
- This last part is not perfect but should work in many cases. It checks if the last value substracted is smaller than its `pmin`. If so, it backtracks once, so that the previous value doesn't use all it's power

### tests

Basic test can be run with `poetry run pytest`. They should all succeed.

### Linting and formatting

I used the library `Ruff` with default options

## Motivation, incomplete parts of the code, doubts, and possible flaws

### Motivation

I decided to go with pandas for this challenge. The idea was to use an easy-to-deploy and reactive use of DataFrames than returns a fast response to the API. On a larger scale, using pySpark would parallelize the work to many executors in memory. Code changes between pandas and Spark DataFrame, but the logic remains the same.

### Incomplete

- The tests are far from exhaustive. Due to time issue, I just did a few simple cases.
- Error management, such as try/except is also minimal for the same reason. The code is not production-ready
- The Dockerfile could be tuned much better. The current one is very simple, resulting in a big image.

### Doubts

- When the `wind%` is 0, windparks are naturally turned off. I chose in the code to append them at the bottom of the response, as part of the sort done on `cost`. It might not be necessary, since `p: 0` is showing and it could impact performance on large scale, but I mostly did it to show I spotted this particular case.

- The mentionned sort is also on `power` and `name`, which are not necessary and could impact performance as well, but the idea was to ensure the smaller amount of powerplants, and to guarantee consistency in executions.

### Flaws

- The algorithm is not optimal. By deciding to sort on `cost` ascending, `power` descending, then a single backtracking, I don't take into account some specific cases such as the one in which a powerplant slightly more expensive than the first one available would have just the necessary `pmin` value.

- Some python libraries have optimizers that solve any case, but the idea of this challenge was to produce an algorithm from scratch.

- The part about CO2 is not done due to time issue.
